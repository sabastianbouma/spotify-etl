{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "from IPython.core.display import clear_output\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Last.fm Connection ###\n",
    "LASTFM_KEY = os.environ.get('LASTFM_KEY')\n",
    "LASTFM_SECRET = os.environ.get('LASTFM_SECRET')\n",
    "LASTFM_USERNAME = 'sabbouma10'\n",
    "LASTFM_NOW_PLAYING = '@attr'\n",
    "LASTFM_URL = 'https://ws.audioscrobbler.com/2.0/'\n",
    "\n",
    "\n",
    "### SQL Connection ###\n",
    "SQL_PASSWORD = os.environ.get('SQL_PASSWORD')\n",
    "SQL_DB = os.environ.get('SQL_DATABASE')\n",
    "engine = create_engine('mysql+mysqlconnector://root:{password}@localhost:3306/{database}'.format(\n",
    "    password = SQL_PASSWORD,\n",
    "    database=SQL_DB\n",
    "))\n",
    "connection = engine.connect()\n",
    "\n",
    "### Spotify Connection ###\n",
    "client_id = os.environ.get('client_id')\n",
    "client_secret = os.environ.get('client_secret')\n",
    "username = os.environ.get('username')\n",
    "playlist_id = os.environ.get('playlist_id')\n",
    "\n",
    "scope = \"playlist-read-private \"\n",
    "scope += \"playlist-modify-public \"\n",
    "scope += \"playlist-modify-private \"\n",
    "scope += \"user-read-playback-state \"\n",
    "scope += \"user-library-read \"\n",
    "scope += \"user-read-recently-played\"\n",
    "\n",
    "token = util.prompt_for_user_token(username,scope,client_id=client_id,client_secret=client_secret,redirect_uri='https://developer.spotify.com/dashboard/applications/09d24c54f26846ffa2d5a8558bec67ec') \n",
    "sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lastfm_get(payload):\n",
    "    headers = {'user-agent': LASTFM_USERNAME}\n",
    "\n",
    "    payload['api_key'] = LASTFM_KEY\n",
    "    payload['format'] = 'json'\n",
    "\n",
    "    response = requests.get(LASTFM_URL, headers=headers, params=payload)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = connection.execute(\"\"\"\n",
    "    SELECT\n",
    "        COUNT(*)\n",
    "    FROM\n",
    "        scrobbles_raw\n",
    "    \"\"\").fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c//200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting page 1/99999\n"
     ]
    }
   ],
   "source": [
    "page = 1\n",
    "total_pages = 99999\n",
    "responses = []\n",
    "old_page = -1\n",
    "page_state = 0\n",
    "with open(\"current_page_lastfm.txt\", \"r\") as f:\n",
    "    try:\n",
    "        old_page = int(f.read()) - 1\n",
    "        page_state = 1\n",
    "    except ValueError as e:\n",
    "        raise ValueError('File does not contain a valid page number')\n",
    "\n",
    "while page <= total_pages:\n",
    "\n",
    "    payload = {\n",
    "        'method': 'user.getrecenttracks',\n",
    "        'user':LASTFM_USERNAME,\n",
    "        'limit':200,\n",
    "        'page':page\n",
    "    }\n",
    "\n",
    "    # print some output so we can see the status\n",
    "    print(\"Requesting page {}/{}\".format(page, total_pages))\n",
    "    # clear the output to make things neater\n",
    "    clear_output(wait = True)\n",
    "\n",
    "    # make the API call\n",
    "    response = lastfm_get(payload)\n",
    "\n",
    "    # if we get an error, print the response and halt the loop\n",
    "    if response.status_code != 200:\n",
    "        print(response.text)\n",
    "        break\n",
    "    if page_state == 1:\n",
    "        total_pages = int(response.json()['recenttracks']['@attr']['totalPages'])\n",
    "        total_pages = total_pages - old_page + 1\n",
    "        page_state = 2\n",
    "    elif page_state == 0:\n",
    "        total_pages = int(response.json()['recenttracks']['@attr']['totalPages'])\n",
    "        \n",
    "    \n",
    "    # extract pagination info\n",
    "    page = int(response.json()['recenttracks']['@attr']['page'])\n",
    "    \n",
    "\n",
    "    # append response\n",
    "    responses.append(response)\n",
    "\n",
    "    # if it's not a cached result, sleep\n",
    "    if not getattr(response, 'from_cache', False):\n",
    "        time.sleep(0.25)\n",
    "\n",
    "    # increment the page number\n",
    "    page += 1\n",
    "\n",
    "with open(\"current_page_lastfm.txt\", \"w\") as f:\n",
    "    f.write(\"{}\".format(page+old_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = r.json()\n",
    "\n",
    "song_names = []\n",
    "artist_names = []\n",
    "album_names = []\n",
    "timestamps = []\n",
    "\n",
    "# Extracting only the relevant bits of data from the json object\n",
    "for response in responses:\n",
    "    data = response.json()      \n",
    "    for song in data['recenttracks'][\"track\"]:\n",
    "        if LASTFM_NOW_PLAYING in song.keys():\n",
    "            continue\n",
    "        song_names.append(song[\"name\"])\n",
    "        artist_names.append(song[\"artist\"][\"#text\"])\n",
    "        album_names.append(song[\"album\"][\"#text\"])\n",
    "        timestamps.append(datetime.datetime.fromtimestamp(int(song['date']['uts'])))\n",
    "    \n",
    "# Prepare a dictionary in order to turn it into a pandas dataframe below       \n",
    "song_dict = {\n",
    "    \"song_name\" : song_names[::-1],\n",
    "    \"artist_name\": artist_names[::-1],\n",
    "    \"album_name\" : album_names[::-1],\n",
    "    \"timestamp\" : timestamps[::-1]\n",
    "}\n",
    "\n",
    "song_df = pd.DataFrame(song_dict, columns = [\"song_name\", \"artist_name\", \"album_name\", \"timestamp\"])\n",
    "\n",
    "while(len(song_df.loc[song_df.duplicated(subset=['timestamp']), 'timestamp'])>0):\n",
    "    song_df.loc[song_df.duplicated(subset=['timestamp']), 'timestamp']+=datetime.timedelta(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = connection.execute(\n",
    "    \"\"\"\n",
    "        SELECT\n",
    "        MAX(timestamp)\n",
    "    FROM\n",
    "        scrobbles_raw\n",
    "    \"\"\"\n",
    ")\n",
    "song_df = song_df.loc[song_df['timestamp']>req.fetchall()[0][0]]\n",
    "song_df.to_sql('scrobbles_raw', con=connection, index=False, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAMES = ['Exmilitary',\n",
    "    'The Perfect Prescription',\n",
    "    'Microphones in 2020',\n",
    "    '2049 (DELUXE EDITION)',\n",
    "    'Guruh Gipsy']\n",
    "LABELS = ['Third Worlds',\n",
    "    'Glass',\n",
    "    'P.W. Elverum & Sun',\n",
    "    'Toasty Digital',\n",
    "    'Pramaqua']\n",
    "ARTS = ['https://e.snmc.io/i/fullres/w/261b220ac09be6686d078e5f7e1a27b1/7024368',\n",
    "    'https://e.snmc.io/i/fullres/w/21af1a0b9cce1179443bd4559ead6385/1448700',\n",
    "    'https://e.snmc.io/i/fullres/w/2a91f1444ba652361e2d58d57c2b33d9/8449827',\n",
    "    'https://e.snmc.io/i/fullres/w/67e3581a08d9378d52383cec624e0011/8438288',\n",
    "    'https://cdn2.albumoftheyear.org/345x/album/78896-guruh-gipsy.jpg']\n",
    "YEARS = [2011, 1987, 2020, 2020, 1977]\n",
    "RELEASE_DATES = [\"2011-05-27\", \"1987-09-01\",\"2020-08-07\",\"2020-09-07\",\"1977-12-01\"]\n",
    "N_TRACKS = [13, 8, 1, 18, 7]\n",
    "\n",
    "local_files = {\n",
    "    NAMES[i]:{\n",
    "        'Label':LABELS[i],\n",
    "        'Year':YEARS[i],\n",
    "        'Release Date':datetime.datetime.strptime(RELEASE_DATES[i], \"%Y-%m-%d\"),\n",
    "        'Album Art':ARTS[i],\n",
    "        'No. Tracks':N_TRACKS[i],\n",
    "        'Popularity':-1,\n",
    "        'Spotify ID':-1\n",
    "    } for i in range(len(NAMES))\n",
    "}\n",
    "FIX_KEYS = ['Green', 'Zombie','New Mexico','Mambo Nassau Remastered','Souvlaki','Wait Long By the River and the Bodies of Your Enemies Will Float By', 'Paebiru']\n",
    "FIX_YEARS = [1986, 1977, 1982, 1981, 1993, 2005, 1975]\n",
    "non_local_files = {FIX_KEYS[i]:FIX_YEARS[i] for i in range(len(FIX_KEYS))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_albums(album_subset:list, all_albums:list):\n",
    "    if len(album_subset)>0:\n",
    "        response = sp.albums(album_subset)\n",
    "        for album in response['albums']:\n",
    "            all_albums.append(album)\n",
    "        print(\"Completed requesting  {}/{} albums \".format(count, max_iter))\n",
    "        clear_output(wait = True)\n",
    "        album_subset = []\n",
    "    return album_subset, all_albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed requesting  497/497 albums \n"
     ]
    }
   ],
   "source": [
    "page = 1\n",
    "total_pages = 9999\n",
    "responses = []\n",
    "limit_playlist = 100\n",
    "\n",
    "while page <= total_pages:\n",
    "    print(\"Requesting playlist page {}/{}\".format(page, total_pages))\n",
    "    clear_output(wait = True)\n",
    "    response = sp.playlist_tracks(playlist_id, fields=None, limit=limit_playlist, offset=(page-1)*limit_playlist, market=None)\n",
    "    if len(response['items']) == 0:\n",
    "        print(\"Failed:\\n{}\".format(response))\n",
    "        break\n",
    "    total_pages = int(int(response['total'])/100)+1\n",
    "    responses.append(response)\n",
    "    page += 1\n",
    "\n",
    "album_ids = [\n",
    "    album['track']['album']['id']\n",
    "    if album['track']['album']['id']!=None\n",
    "    else album['track']\n",
    "    for response in responses\n",
    "    for album in response['items']\n",
    "]\n",
    "\n",
    "added_ats = [\n",
    "    datetime.datetime.strptime(album['added_at'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    for response in responses\n",
    "    for album in response['items']\n",
    "]\n",
    "\n",
    "max_iter = len(album_ids)\n",
    "count = 0\n",
    "lim=20\n",
    "all_albums = []\n",
    "album_subset = []\n",
    "\n",
    "while count<max_iter:\n",
    "    album_id = album_ids[count]\n",
    "    if type(album_id)!=str:\n",
    "        album_subset, all_albums = add_albums(album_subset, all_albums)\n",
    "        all_albums.append(album_id)\n",
    "    elif len(album_subset)<lim:\n",
    "        album_subset.append(album_id)\n",
    "    else:\n",
    "        album_subset, all_albums = add_albums(album_subset, all_albums)\n",
    "        continue\n",
    "    count+=1\n",
    "    if count==max_iter:\n",
    "        album_subset, all_albums = add_albums(album_subset, all_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_names = []\n",
    "artist_names = []\n",
    "release_dates = []\n",
    "years = []\n",
    "n_tracks = []\n",
    "labels = []\n",
    "popularities = []\n",
    "spotify_ids = []\n",
    "album_arts = []\n",
    "\n",
    "for album in all_albums:\n",
    "    if album['type']=='track':\n",
    "        name = album['album']['name']\n",
    "        album_names.append(name)\n",
    "        artist_names.append(album['artists'][0]['name'])\n",
    "        if name in local_files.keys():\n",
    "            local_album = local_files[name]\n",
    "            release_dates.append(local_album['Release Date'])\n",
    "            years.append(local_album['Year'])\n",
    "            n_tracks.append(local_album['No. Tracks'])\n",
    "            labels.append(local_album['Label'])\n",
    "            popularities.append(local_album['Popularity'])\n",
    "            spotify_ids.append(local_album['Spotify ID'])\n",
    "            album_arts.append(local_album['Album Art'])\n",
    "    \n",
    "    else:\n",
    "        name = album['name']\n",
    "        album_names.append(name)\n",
    "        artist_names.append(album['artists'][0]['name'])\n",
    "        date = album['release_date']\n",
    "        try:\n",
    "            release_date = datetime.datetime.strptime(date, \"%Y-%m-%d\").date()\n",
    "        except:\n",
    "            try:\n",
    "                release_date = datetime.datetime.strptime(date, \"%Y\").date()\n",
    "            except:\n",
    "                release_date = datetime.datetime.strptime(date, \"%Y-%m\").date()\n",
    "        release_dates.append(release_date)\n",
    "        if name in non_local_files.keys():\n",
    "            years.append(non_local_files[name])     \n",
    "        else:\n",
    "            years.append(release_date.year)\n",
    "        n_tracks.append(int(album['total_tracks']))\n",
    "        labels.append(album['label'])\n",
    "        popularities.append(int(album['popularity']))\n",
    "        spotify_ids.append(album['id'])\n",
    "        album_arts.append(album['images'][0]['url'])\n",
    "\n",
    "album_dict = {\n",
    "    \"Album\":album_names,\n",
    "    \"Album_Artist\":artist_names,\n",
    "    \"Release_Date\":release_dates,\n",
    "    \"Year\":years,\n",
    "    \"No._Tracks\":n_tracks,\n",
    "    \"Label\":labels,\n",
    "    \"Popularity\":popularities,\n",
    "    \"Spotify_ID\":spotify_ids,\n",
    "    \"Album_Art\":album_arts,\n",
    "    \"Date_Added\":added_ats\n",
    "}\n",
    "\n",
    "spotify_album_df = pd.DataFrame(album_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = connection.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        Spotify_ID\n",
    "    FROM\n",
    "        spotify_albums_raw;\n",
    "    \"\"\"\n",
    ")\n",
    "ids = [i[0] for i in req.fetchall()]\n",
    "spotify_album_df = spotify_album_df.loc[~spotify_album_df['Spotify_ID'].astype(str).isin(ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = connection.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        MAX(spotify_albums_raw.index)\n",
    "    FROM\n",
    "        spotify_albums_raw\n",
    "    \"\"\"\n",
    ")\n",
    "current_index = req.fetchall()[0][0]+1\n",
    "spotify_album_df.index = range(current_index, current_index +len(spotify_album_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime(2021,11,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    artists_df = pd.read_sql('artists_raw', con=connection)\n",
    "    current_index = max(artists_df['index'])\n",
    "    indexes = []\n",
    "    new_indexes = []\n",
    "    new_artists = []\n",
    "    for i in spotify_album_df.index:\n",
    "        try:\n",
    "            indexes.append(artists_df.loc[artists_df['Name']==spotify_album_df.loc[i,'Album_Artist'], 'index'].iloc[0])\n",
    "        except:\n",
    "            current_index+=1\n",
    "            indexes.append(current_index)\n",
    "            new_indexes.append(current_index)\n",
    "            new_artists.append(spotify_album_df.loc[i,'Album_Artist'])\n",
    "    spotify_album_df['Album_Artist_ID'] = indexes\n",
    "    new_artists_df = pd.DataFrame(new_artists, index=new_indexes, columns=['Name'])\n",
    "except:\n",
    "    new_artists_df = pd.DataFrame(spotify_album_df['Album_Artist'].unique(), columns=['Name'])\n",
    "    spotify_album_df['Album_Artist_ID'] = [artists_df.loc[artists_df['Name']==i].index[0] for i in spotify_album_df['Album_Artist']]\n",
    "\n",
    "new_artists_df.to_sql('artists_raw', con=connection, if_exists='append')\n",
    "spotify_album_df.drop('Album_Artist',axis=1, inplace=True)\n",
    "spotify_album_df.to_sql('spotify_albums_raw', con=connection, if_exists='append')\n",
    "\n",
    "try:\n",
    "    connection.execute(\n",
    "        \"\"\"\n",
    "        ALTER TABLE `spotify`.`artists_raw` \n",
    "        CHANGE COLUMN `index` `index` BIGINT NOT NULL ,\n",
    "        CHANGE COLUMN `Name` `Name` TEXT NOT NULL ,\n",
    "        ADD PRIMARY KEY (`index`),\n",
    "        ADD UNIQUE INDEX `index_UNIQUE` (`index` ASC) VISIBLE;\n",
    "        ;\n",
    "        \"\"\"\n",
    "    )\n",
    "    connection.execute(\n",
    "        \"\"\"\n",
    "        ALTER TABLE `spotify`.`spotify_albums_raw` \n",
    "        CHANGE COLUMN `index` `index` BIGINT NOT NULL ,\n",
    "        CHANGE COLUMN `Album` `Album` TEXT NOT NULL ,\n",
    "        CHANGE COLUMN `Album_Artist_ID` `Album_Artist_ID` BIGINT NOT NULL ,\n",
    "        CHANGE COLUMN `Release_Date` `Release_Date` DATETIME NOT NULL ,\n",
    "        CHANGE COLUMN `Year` `Year` BIGINT NOT NULL ,\n",
    "        CHANGE COLUMN `No._Tracks` `No._Tracks` BIGINT NOT NULL ,\n",
    "        CHANGE COLUMN `Label` `Label` TEXT NOT NULL ,\n",
    "        CHANGE COLUMN `Popularity` `Popularity` BIGINT NOT NULL ,\n",
    "        CHANGE COLUMN `Spotify_ID` `Spotify_ID` TEXT NOT NULL ,\n",
    "        CHANGE COLUMN `Album_Art` `Album_Art` TEXT NOT NULL ,\n",
    "        CHANGE COLUMN `Date_Added` `Date_Added` DATETIME NOT NULL ,\n",
    "        ADD PRIMARY KEY (`index`),\n",
    "        ADD UNIQUE INDEX `index_UNIQUE` (`index` ASC) VISIBLE;\n",
    "        ;\n",
    "        \"\"\"\n",
    "    )\n",
    "except:\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "itunes_songs = pd.read_csv(\"all_itunes_tracks_spot\")\n",
    "itunes_songs.loc[itunes_songs['Disk Number'].isna(), 'Disk Number'] = 1\n",
    "itunes_songs['Disk Number'] = itunes_songs['Disk Number'].astype(int)\n",
    "itunes_songs['Track Number'] = itunes_songs['Track Number'].astype(int)\n",
    "itunes_songs['Time'] = itunes_songs['Time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_album_df = pd.read_sql('spotify_albums_raw', con=connection)\n",
    "artists_df = pd.read_sql('artists_raw', con=connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_names = []\n",
    "spotify_song_ids = []\n",
    "track_album_ids = []\n",
    "artist_names = []\n",
    "times = []\n",
    "explicits = []\n",
    "track_nos = []\n",
    "disc_nos = []\n",
    "\n",
    "for album in all_albums:\n",
    "    if album['type']=='track':\n",
    "        name = album['album']['name']\n",
    "        artist = album['artists'][0]['name']\n",
    "        tracks = itunes_songs.loc[itunes_songs['Album']==name]\n",
    "        track_names+=list(tracks['Name'])\n",
    "        spotify_song_ids+=[-1]*len(tracks)\n",
    "        album_id = spotify_album_df.loc[(spotify_album_df['Album']==name)].index[0]\n",
    "        track_album_ids+=[album_id]*len(tracks)\n",
    "        artist_names+=[artist]*len(tracks)\n",
    "        times+=list(tracks['Time'])\n",
    "        explicits+=[-1]*len(tracks)\n",
    "        track_nos+=list(tracks['Track Number'])\n",
    "        disc_nos+=list(tracks['Disk Number'])\n",
    "        \n",
    "    else:\n",
    "        album_id = spotify_album_df.loc[spotify_album_df['Spotify_ID']==album['id']].index[0]\n",
    "\n",
    "        track_album_ids+=[album_id]*len(album['tracks']['items'])\n",
    "        for track in album['tracks']['items']:\n",
    "            track_names.append(track['name'])\n",
    "            spotify_song_ids.append(track['id'])\n",
    "            artist_names.append(track['artists'][0]['name'] )\n",
    "            times.append(int(track['duration_ms']/1000))\n",
    "            explicits.append(track['explicit'])\n",
    "            track_nos.append(track['track_number'])\n",
    "            disc_nos.append(track['disc_number'])\n",
    "            \n",
    "\n",
    "spotify_songs_dict = {\n",
    "    \"Name\":track_names,\n",
    "    \"Artist\":artist_names,\n",
    "    \"Time\":times,\n",
    "    \"Explicit\":explicits,\n",
    "    \"Track_No.\":track_nos,\n",
    "    \"Disc_No.\":disc_nos,\n",
    "    \"Spotify_Song_ID\":spotify_song_ids,\n",
    "    \"Album_ID\":track_album_ids\n",
    "}\n",
    "spotify_songs_df = pd.DataFrame(spotify_songs_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = connection.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        Spotify_Song_ID\n",
    "    FROM\n",
    "        spotify_tracks_raw;\n",
    "    \"\"\"\n",
    ")\n",
    "ids = [i[0] for i in req.fetchall()]\n",
    "spotify_songs_df = spotify_songs_df.loc[~spotify_songs_df['Spotify_Song_ID'].astype(str).isin(ids)]\n",
    "\n",
    "req = connection.execute(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        MAX(spotify_tracks_raw.index)\n",
    "    FROM\n",
    "        spotify_tracks_raw\n",
    "    \"\"\"\n",
    ")\n",
    "current_index = req.fetchall()[0][0]+1\n",
    "spotify_songs_df.index = range(current_index, current_index +len(spotify_songs_df))\n",
    "\n",
    "spotify_songs_df['Artist_ID'] = [artists_df.loc[artists_df['Name']==i].index[0] if len(artists_df.loc[artists_df['Name']==i])>0 else -1 for i in spotify_songs_df['Artist']]\n",
    "spotify_songs_df.drop('Artist',axis=1, inplace=True)\n",
    "\n",
    "spotify_songs_df.to_sql('spotify_tracks_raw', con=connection, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d1e997bfa4e8a21f71bb42567cb5e702d28b7a563c5cbd58154ee73a197b8c9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
